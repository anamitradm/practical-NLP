{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/axel-sirota/practical-nlp/blob/main/1-similarity/Practical_NLP_3_Doc2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZMSZTJFAflJf"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import smart_open\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "embedding_dim = 100\n",
    "vocabulary_size_to_use = 50000\n",
    "epochs = 10\n",
    "train_file_path = './train_yelp.csv'\n",
    "test_file_path = './test_yelp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhPGYNHngORV",
    "outputId": "32af3d27-84eb-46d5-8051-b59d4571dba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_data.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_data.sh\n",
    "if [ ! -f yelp.csv ]; then\n",
    "  wget -O yelp.csv https://www.dropbox.com/s/xds4lua69b7okw8/yelp.csv?dl=0\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OIkEglxYkHa4"
   },
   "outputs": [],
   "source": [
    "!bash get_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MdhWQqKZkTaR"
   },
   "outputs": [],
   "source": [
    "path = './yelp.csv'\n",
    "yelp = pd.read_csv(path)\n",
    "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
    "X = yelp_best_worst.text\n",
    "y = yelp_best_worst.stars.map({1:0, 5:1})\n",
    "y = yelp_best_worst.stars.map({1:0, 5:1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train.to_csv(train_file_path, header=False, index=False, columns=['text'])\n",
    "X_test.to_csv(test_file_path, header=False, index=False, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GghYGYNrkeT-"
   },
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)  # ' I like ice cream'  -> ['i', 'like', 'ice', 'cream']\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "41pIWjw5mI0R"
   },
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(train_file_path))[:vocabulary_size_to_use]\n",
    "test_corpus = list(read_corpus(test_file_path, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fg-6ZGbumYD4",
    "outputId": "1775ef6d-29b7-4ee9-bfd0-5e9889e28914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['if', 'could', 'give', 'it', 'more', 'than', 'would', 'sweet', 'pea', 'and', 'live', 'down', 'the', 'street', 'literally', 'down', 'the', 'street', 'from', 'this', 'bar', 'we', 'waited', 'for', 'it', 'to', 'open', 'for', 'what', 'seemed', 'like', 'decades', 'praying', 'that', 'this', 'was', 'going', 'to', 'be', 'the', 'type', 'of', 'place', 'that', 'could', 'become', 'our', 'local', 'it', 'has', 'exceeded', 'our', 'expectations', 'the', 'atmosphere', 'is', 'amazing', 'the', 'drinks', 'are', 'amazing', 'every', 'last', 'one', 'of', 'them', 'but', 'the', 'margaritas', 'are', 'the', 'best', 've', 'ever', 'had', 'they', 'tasted', 'like', 'fresh', 'squeeze', 'of', 'sunshine', 'that', 'makes', 'me', 'happy', 'inside', 'margarita', 'mondays', 'margs', 'and', 'free', 'food', 'happy', 'hours', 'are', 'amazing', 'new', 'year', 'eve', 'last', 'year', 'was', 'amazing', 'the', 'year', 'anniversary', 'party', 'was', 'amazing', 'but', 'most', 'of', 'all', 'the', 'owner', 'and', 'staff', 'are', 'some', 'of', 'the', 'coolest', 'peeps', 'that', 'you', 'll', 'ever', 'meet', 'go', 'here', 'you', 'will', 'love', 'it'], tags=[0]), TaggedDocument(words=['we', 'had', 'fantastic', 'experience', 'here', 'we', 'went', 'on', 'thursday', 'evening', 'and', 'with', 'the', 'misters', 'on', 'it', 'was', 'still', 'very', 'pleasant', 'sitting', 'outside', 'even', 'in', 'june', 'the', 'wine', 'list', 'was', 'extremely', 'affordable', 'most', 'between', 'and', 'for', 'scottsdale', 'this', 'is', 'steal', 'we', 'shared', 'an', 'appetizer', 'and', 'main', 'entree', 'the', 'appetizer', 'was', 'delish', 'grilled', 'bread', 'perfectly', 'grilled', 'not', 'so', 'hard', 'that', 'it', 'hurts', 'your', 'gums', 'with', 'three', 'spreads', 'an', 'amazing', 'goat', 'cheese', 'and', 'marscapone', 'eggplant', 'and', 'hummus', 'also', 'they', 'serve', 'house', 'bread', 'with', 'great', 'sun', 'dried', 'tomato', 'butter', 'for', 'our', 'entree', 'we', 'shared', 'the', 'fish', 'special', 'which', 'was', 'sea', 'bass', 'with', 'artichokes', 'fingerling', 'potatoes', 'and', 'spinach', 'fantastic', 'the', 'service', 'was', 'also', 'great'], tags=[1])]\n"
     ]
    }
   ],
   "source": [
    "print(train_corpus[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "R95ZH6okmZ3Z"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=embedding_dim, min_count=2, epochs=epochs, workers=5)\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-1Y0gLAumcEJ"
   },
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XLPfSgXmdYr",
    "outputId": "576a1bee-5c19-45c1-bd18-25da24209c7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04697444  0.02877179  0.00197103  0.00176261 -0.04424812 -0.10461224\n",
      "  0.03244643  0.05416036 -0.07026895  0.00257482  0.03210533 -0.0506878\n",
      "  0.00201686  0.00659462  0.02546122 -0.02567191  0.03484739 -0.01378562\n",
      "  0.01637085 -0.05976913  0.05574014  0.03910057  0.03734747 -0.05033958\n",
      " -0.05854894 -0.00663432 -0.06904349 -0.02832006 -0.02064372 -0.03622911\n",
      "  0.03930648  0.0045964   0.01615743 -0.05271109 -0.00996348  0.01414592\n",
      "  0.05090109 -0.03366894 -0.0433057  -0.06742075  0.01101882 -0.07000057\n",
      "  0.01633526 -0.00498816 -0.02093288 -0.01915625 -0.05492952 -0.01395677\n",
      " -0.05535625  0.02585294  0.01661433 -0.01738672 -0.01116242 -0.03142674\n",
      " -0.02715968  0.04111617  0.00095678  0.00482185 -0.04075468 -0.02324656\n",
      "  0.02286347 -0.00769972 -0.05162548  0.00200101 -0.06422206  0.10389072\n",
      "  0.01468617  0.08428773 -0.03896919  0.06988147 -0.00429043  0.02294633\n",
      "  0.0713889   0.00587143  0.08054425  0.0689339  -0.01796136  0.04527169\n",
      " -0.04427878 -0.03100914 -0.01562753  0.03802808 -0.00148667  0.05077842\n",
      "  0.03522637 -0.0051349   0.00513896  0.03270612  0.02458897  0.05001037\n",
      "  0.07063273 -0.00863824 -0.01213273  0.02745197  0.05613133  0.05935454\n",
      "  0.03444457 -0.02868592 -0.00383194  0.03631456]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(gensim.utils.simple_preprocess('only you can prevent. \\n forest fires'))\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksHb8OJUmeVo",
    "outputId": "5c246557-4cdd-425a-9ad4-58dd7d79297f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (1315): «we had an extremely atypical experience at the royal palms our first night have no question about that but they more than made up for it they were gracious they smiled they apologized and they made it right immediately can ask for anything more from that from place that prides itself in its customer service»\n",
      "\n",
      "MOST SIMILAR (3695, 0.678717851638794): «it seems like cutting something in half so we could easily share it particularly after the plate has been delivered to the table for us to appreciate it beauty and after we ve communicated to our server and demonstrated with the first two courses that we were splitting the items is in the vein of nothing fancy»\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/jqvp4xxs5pn4cds1xb9339xm0000gn/T/ipykernel_27902/2410382607.py:4: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the train corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'MOST SIMILAR %s: «%s»\\n' % (sims[0], ' '.join(train_corpus[sims[0][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DiA0qzWmjt9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhBB28lUooO1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO0xeC7LgjYjScivZd/2XQc",
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
